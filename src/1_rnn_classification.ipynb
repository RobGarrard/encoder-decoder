{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Name classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the exercise from this pytorch tutorial:\n",
    "\n",
    "[https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html](https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html)\n",
    "\n",
    "We've already downloaded and curated the data.\n",
    "\n",
    "The raw data contains a set of files, where the file name is a country; and each line of the file is a name originating from that country.\n",
    "\n",
    "The challenge is use an RNN that reads letter-by-letter and classifies a name according to its country of origin.\n",
    "\n",
    "We've processed the raw data so that we now have two files: `names_indices.txt` and `countries_word_indices.txt`. In the former, we've tokenized each name into its component letters, not transforming to lowercase, and then converted each token to its index in the vocabulary. We also added sos/eos tokens on the front and end of the names. In the latter, we've done the same process but treated the whole name of the country as a token and didn't wrap it with special tokens.\n",
    "\n",
    "Let's play with PyTorch Lightning. We'll run this classification problem 3 times, having the base RNN be a vanilla RNN, an LSTM, and a GRU. We'll take a look at the metrics logged with Tensorboard to see if there's a big difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import yaml\n",
    "\n",
    "import torch\n",
    "import lightning as L\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from pytorch_lightning import seed_everything\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.utilities.model_summary import ModelSummary\n",
    "from lightning.pytorch.callbacks import LearningRateMonitor\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from common.language import load_language\n",
    "\n",
    "from common.dataloaders import (\n",
    "    TranslationDataset,\n",
    "    padding_collator,\n",
    ")\n",
    "\n",
    "from common.models import (\n",
    "    RNNClassifier,\n",
    ")\n",
    "\n",
    "from common.utils import (\n",
    "    get_logger,\n",
    "    Timer,\n",
    ")\n",
    "\n",
    "logger = get_logger(\"name_classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "seed_everything(2718)\n",
    "\n",
    "# Set the cwd to the root of the project.\n",
    "# Only let this execute once\n",
    "if os.getcwd().endswith(\"src\"):\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "logger.info(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config.yaml. This contains all of our paths and constants.\n",
    "with open(\"config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Training params\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 128\n",
    "EMBEDDING_SIZE = 512\n",
    "HIDDEN_SIZE = 512\n",
    "NUM_LAYERS = 1\n",
    "DROPOUT = 0.0  # Dropout is between rnn layers\n",
    "\n",
    "# Trainer params\n",
    "UNIT_TYPE = \"GRU\"  # GRU or LSTM or RNN\n",
    "ACCELERATOR = \"gpu\"  # \"cpu\" or \"gpu\"\n",
    "\n",
    "# CPUS to give each dataloader\n",
    "NUM_WORKERS = 3\n",
    "\n",
    "# Every time you run training, the logs will have this tag attached.\n",
    "# If you rerun with the same tag, the log will be overwritten.\n",
    "TAG = (\n",
    "    f\"UNIT={UNIT_TYPE}_\"\n",
    "    f\"BATCH_SIZE={BATCH_SIZE}_\"\n",
    "    f\"EMBEDDING_SIZE={EMBEDDING_SIZE}_\"\n",
    "    f\"HIDDEN_SIZE={HIDDEN_SIZE}_\"\n",
    "    f\"LAYERS={NUM_LAYERS}_\"\n",
    "    f\"DROPOUT={DROPOUT}_\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the language models\n",
    "names_language = load_language(config[\"NAMES_LANGUAGE_MODEL_PATH\"])\n",
    "\n",
    "# Use the country model where we didn't split up the word into letters.\n",
    "countries_language = load_language(config[\"COUNTRIES_WORD_LANGUAGE_MODEL_PATH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAMES_VOCAB_SIZE = len(names_language.vocabulary)\n",
    "COUNTRIES_VOCAB_SIZE = len(countries_language.vocabulary)\n",
    "\n",
    "print(f\"Names vocab size: {NAMES_VOCAB_SIZE}\")\n",
    "print(f\"Countries vocab size: {COUNTRIES_VOCAB_SIZE}\")\n",
    "\n",
    "# Vocabulary attributes are a dictionary with the token being the\n",
    "# key and the index being how frequently the token appears in the corpus.\n",
    "# Note that since we've added the special tokens ourselves, they will\n",
    "# have frequency 0.\n",
    "name_vocab = list(names_language.vocabulary.keys())\n",
    "country_vocab = list(countries_language.vocabulary.keys())\n",
    "\n",
    "print(\"Top 10 most common tokens in names vocabulary:\")\n",
    "for i in range(10):\n",
    "    print(f\"{name_vocab[i]}: {names_language.vocabulary[name_vocab[i]]}\")\n",
    "\n",
    "print(\"\\nTop 10 most common tokens in countries vocabulary:\")\n",
    "for i in range(10):\n",
    "    print(\n",
    "        f\"{country_vocab[i]}: {countries_language.vocabulary[country_vocab[i]]}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there's some class imbalance. Russian names dominate this data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TranslationDataset(\n",
    "    source_labels_path=config[\"NAMES_INPUT_PATH\"],\n",
    "    target_labels_path=config[\"COUNTRIES_INPUT_PATH\"],\n",
    "    source_indices_path=config[\"NAMES_OUTPUT_PATH\"],\n",
    "    target_indices_path=config[\"COUNTRIES_WORD_OUTPUT_PATH\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show random example\n",
    "x, y, name, country = dataset[np.random.randint(0, len(dataset))]\n",
    "print(\"Input: \", x)\n",
    "print(\"Target: \", y)\n",
    "print(\"Name: \", name)\n",
    "print(\"Country: \", country)\n",
    "\n",
    "# Note that the input always begins with 2 <SOS> and ends with 3 <EOS>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = torch.utils.data.random_split(dataset, [0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataloaders\n",
    "# We use a collate function to pad the sequences to the same length.\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    collate_fn=padding_collator,\n",
    ")\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    collate_fn=padding_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch from the dataloader\n",
    "x, y, names, countries = next(iter(train_dataloader))\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(names)\n",
    "print(countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNClassifier(\n",
    "    input_size=NAMES_VOCAB_SIZE,\n",
    "    output_size=COUNTRIES_VOCAB_SIZE,\n",
    "    embedding_size=EMBEDDING_SIZE,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    unit_type=UNIT_TYPE,\n",
    "    epochs=EPOCHS,\n",
    "    data_length=len(train_data),\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dropout=DROPOUT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelSummary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that we can forward pass with the x generated above.\n",
    "\n",
    "output, hidden = model(x)\n",
    "\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "\n",
    "# If hidden is a tuple, then it came from an LSTM.\n",
    "# Split it up into the hidden and cell states.\n",
    "if isinstance(hidden, tuple):\n",
    "    hidden, cell = hidden\n",
    "\n",
    "print(f\"Hidden shape: {hidden.shape}\")\n",
    "\n",
    "# Output is (batch, seq_len, output_size)\n",
    "# Hidden is (num_layers, batch, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print how many parameters the model has\n",
    "print(\n",
    "    f\"Model has {sum(p.numel() for p in model.parameters() if p.requires_grad):,} parameters.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training logs\n",
    "\n",
    "tensorboard_logger = TensorBoardLogger(\n",
    "    save_dir=config[\"TENSORBOARD_LOGS_PATH\"],\n",
    "    name=\"name-classification/\",\n",
    "    version=TAG,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use our nominated accelerator and log to tensorboard\n",
    "trainer = L.Trainer(\n",
    "    devices=1,\n",
    "    accelerator=ACCELERATOR,\n",
    "    logger=tensorboard_logger,\n",
    "    max_epochs=EPOCHS,\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor=\"validation_loss\", patience=3, mode=\"min\"),\n",
    "        LearningRateMonitor(logging_interval=\"step\"),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer = Timer()\n",
    "trainer.fit(model, train_dataloader, val_dataloader)\n",
    "print(f\"Elapsed time: {timer.toc()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.freeze()\n",
    "trainer.test(model, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), config[\"NAME_CLASSIFICATION_TORCH_MODEL_PATH\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the model over the validation set to get actual and predicted.\n",
    "# Can probably do this more efficiently\n",
    "\n",
    "model.eval()\n",
    "actual = []\n",
    "predicted = []\n",
    "\n",
    "for x, y, name, country in val_data:\n",
    "    output, _ = model(x.unsqueeze(0))\n",
    "\n",
    "    # Pull out the output fir the last token\n",
    "    output = output[:, -1, :]\n",
    "\n",
    "    # argmax to get the index of the highest value\n",
    "    predicted_country_index = torch.argmax(output).item()\n",
    "\n",
    "    # Use the language model to get the country name\n",
    "    predicted_country = countries_language.index_to_token(\n",
    "        predicted_country_index\n",
    "    )\n",
    "\n",
    "    actual.append(country)\n",
    "    predicted.append(predicted_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(actual, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sorted(list(set(actual).union(set(predicted))))\n",
    "cm = confusion_matrix(actual, predicted, labels=labels, normalize=\"true\")\n",
    "cm = np.round(cm, 2)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "ax = plt.gca()\n",
    "\n",
    "ConfusionMatrixDisplay(cm, display_labels=labels).plot(ax=ax)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

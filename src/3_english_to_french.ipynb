{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English-to-French Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, this is a harder task and a bigger data set. It'll take a little while longer to train this one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import yaml\n",
    "\n",
    "import torch\n",
    "import lightning as L\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from pytorch_lightning import seed_everything\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.utilities.model_summary import ModelSummary\n",
    "from lightning.pytorch.callbacks import LearningRateMonitor\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from common.language import load_language\n",
    "\n",
    "from common.dataloaders import (\n",
    "    TranslationDataset,\n",
    "    padding_collator,\n",
    ")\n",
    "\n",
    "from common.models import (\n",
    "    EncoderDecoder,\n",
    ")\n",
    "\n",
    "from common.utils import (\n",
    "    get_logger,\n",
    "    Timer,\n",
    ")\n",
    "\n",
    "logger = get_logger(\"english-to-french-translation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(2718)\n",
    "\n",
    "# Set the cwd to the root of the project.\n",
    "# Only let this execute once\n",
    "if os.getcwd().endswith(\"src\"):\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "logger.info(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config.yaml. This contains all of our paths and constants.\n",
    "with open(\"config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Training params\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 128\n",
    "EMBEDDING_SIZE = 128\n",
    "HIDDEN_SIZE = 1024\n",
    "SCHEDULER = \"onecycle\"  # \"onecycle\" or \"reduceonplateau\"\n",
    "\n",
    "# No unit type option here, just using GRUs. No multiple layers yet.\n",
    "\n",
    "# Trainer params\n",
    "ACCELERATOR = \"gpu\"  # \"cpu\" or \"gpu\"\n",
    "\n",
    "# CPUS to give each dataloader\n",
    "NUM_WORKERS = 3\n",
    "\n",
    "# Every time you run training, the logs will have this tag attached.\n",
    "# If you rerun with the same tag, the log will be overwritten.\n",
    "TAG = (\n",
    "    f\"en-to-fr_\"\n",
    "    f\"{SCHEDULER}_\"\n",
    "    f\"BATCH_SIZE={BATCH_SIZE}_\"\n",
    "    f\"EMBEDDING_SIZE={EMBEDDING_SIZE}_\"\n",
    "    f\"HIDDEN_SIZE={HIDDEN_SIZE}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_language = load_language(config[\"ENGLISH_LANGUAGE_MODEL_PATH\"])\n",
    "french_language = load_language(config[\"FRENCH_LANGUAGE_MODEL_PATH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAMES_VOCAB_SIZE = len(english_language.vocabulary)\n",
    "COUNTRIES_VOCAB_SIZE = len(french_language.vocabulary)\n",
    "\n",
    "print(f\"Names vocab size: {NAMES_VOCAB_SIZE}\")\n",
    "print(f\"Countries vocab size: {COUNTRIES_VOCAB_SIZE}\")\n",
    "\n",
    "# Vocabulary attributes are a dictionary with the token being the\n",
    "# key and the index being how frequently the token appears in the corpus.\n",
    "# Note that since we've added the special tokens ourselves, they will\n",
    "# have frequency 0.\n",
    "name_vocab = list(english_language.vocabulary.keys())\n",
    "country_vocab = list(french_language.vocabulary.keys())\n",
    "\n",
    "print(\"Top 10 most common tokens in names vocabulary:\")\n",
    "for i in range(10):\n",
    "    print(f\"{name_vocab[i]}: {english_language.vocabulary[name_vocab[i]]}\")\n",
    "\n",
    "print(\"\\nTop 10 most common tokens in countries vocabulary:\")\n",
    "for i in range(10):\n",
    "    print(f\"{country_vocab[i]}: {french_language.vocabulary[country_vocab[i]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TranslationDataset(\n",
    "    source_labels_path=config[\"ENGLISH_INPUT_PATH\"],\n",
    "    target_labels_path=config[\"FRENCH_INPUT_PATH\"],\n",
    "    source_indices_path=config[\"ENGLISH_OUTPUT_PATH\"],\n",
    "    target_indices_path=config[\"FRENCH_OUTPUT_PATH\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show random example\n",
    "x, y, english, french = dataset[np.random.randint(0, len(dataset))]\n",
    "print(\"Input: \", x)\n",
    "print(\"Target: \", y)\n",
    "print(\"english: \", english)\n",
    "print(\"french: \", french)\n",
    "\n",
    "# Note that both source and target languages have <SOS> and  <EOS> tokens now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = torch.utils.data.random_split(dataset, [0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataloaders\n",
    "# We use a collate function to pad the sequences to the same length.\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    collate_fn=padding_collator,\n",
    ")\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    collate_fn=padding_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the data loader.\n",
    "\n",
    "x, y, english, french = next(iter(train_dataloader))\n",
    "print(\"Source shape: \", x.shape)\n",
    "print(\"Target shape: \", y.shape)\n",
    "\n",
    "\n",
    "# Just to be sure, detokenize the first row\n",
    "print(\"\\nDetokenize the first row\")\n",
    "print(\"Source: \", english_language.index_to_token(x[0]))\n",
    "print(\"Target: \", french_language.index_to_token(y[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EncoderDecoder(\n",
    "    source_language=english_language,\n",
    "    target_language=french_language,\n",
    "    detokenizer=lambda s: \" \".join(s),\n",
    "    input_size=NAMES_VOCAB_SIZE,\n",
    "    output_size=COUNTRIES_VOCAB_SIZE,\n",
    "    embedding_size=EMBEDDING_SIZE,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    data_length=len(train_data),\n",
    "    max_output_length=30,\n",
    "    scheduler=SCHEDULER,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelSummary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that we can forward pass with the x,y generated above.\n",
    "\n",
    "context_vector = model.encoder_step(x)\n",
    "print(f\"Context vector shape: {context_vector.shape}\")\n",
    "\n",
    "output, hidden = model.decoder_step(y[:, :-1], context_vector, context_vector)\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Hidden shape: {hidden.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print how many parameters the model has\n",
    "print(\n",
    "    f\"Model has {sum(p.numel() for p in model.parameters() if p.requires_grad):,} parameters.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so that's a little bigger than previously. Most of these are in the dense layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training logs\n",
    "\n",
    "tensorboard_logger = TensorBoardLogger(\n",
    "    save_dir=config[\"TENSORBOARD_LOGS_PATH\"],\n",
    "    name=\"english-to-french-translation/\",\n",
    "    version=TAG,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use our nominated accelerator and log to tensorboard\n",
    "trainer = L.Trainer(\n",
    "    devices=1,\n",
    "    accelerator=ACCELERATOR,\n",
    "    logger=tensorboard_logger,\n",
    "    max_epochs=EPOCHS,\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor=\"validation_loss\", patience=3, mode=\"min\"),\n",
    "        LearningRateMonitor(logging_interval=\"step\"),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer = Timer()\n",
    "trainer.fit(model, train_dataloader, val_dataloader)\n",
    "print(f\"Elapsed time: {timer.toc()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(\n",
    "    model.state_dict(), config[\"ENGLISH_TO_FRENCH_TRANSLATION_MODEL_PATH\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.freeze()\n",
    "\n",
    "english_sentences = [\n",
    "    \"Do you speak English?\",\n",
    "    \"Where is the library?\",\n",
    "    \"I think, therefore I am.\",\n",
    "    \"Where is my wine and my cheese? Do you have it?\",\n",
    "]\n",
    "\n",
    "expected_french_sentences = [\n",
    "    \"Parlez-vous anglais?\",\n",
    "    \"Où est la bibliothèque?\",\n",
    "    \"Je pense, donc je suis.\",\n",
    "    \"Où est mon vin et mon fromage? L'avez-vous?\",\n",
    "]\n",
    "\n",
    "for sentence, target in zip(english_sentences, expected_french_sentences):\n",
    "    translated = model.inference(sentence)\n",
    "    print(f\"Input: {sentence}\")\n",
    "    print(f\"Target: {target}\")\n",
    "    print(f\"Output: {translated}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cases from the training set\n",
    "\n",
    "for i in range(5):\n",
    "    x, y, english, french = train_data[i]\n",
    "    translated = model.inference(english)\n",
    "    print(f\"Input: {english}\")\n",
    "    print(f\"Target: {french}\")\n",
    "    print(f\"Output: {translated}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What about some cases from the validation data set?\n",
    "\n",
    "for i in range(5):\n",
    "    x, y, english, french = val_data[i]\n",
    "    translated = model.inference(english)\n",
    "    print(f\"Input: {english}\")\n",
    "    print(f\"Target: {french}\")\n",
    "    print(f\"Output: {translated}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
